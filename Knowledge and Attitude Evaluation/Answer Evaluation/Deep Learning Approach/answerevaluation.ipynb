{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.metrics import sparse_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "asag_df = pd.read_csv('../Data/merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2442 entries, 0 to 2441\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Question_ID   2442 non-null   float64\n",
      " 1   Question      2442 non-null   object \n",
      " 2   Model_Answer  2442 non-null   object \n",
      " 3   Answer        2442 non-null   object \n",
      " 4   Score         2442 non-null   float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 95.5+ KB\n"
     ]
    }
   ],
   "source": [
    "asag_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To simulate the behaviour of portions of the desired software product. \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asag_df['Model_Answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.617936117936118\n"
     ]
    }
   ],
   "source": [
    "# average num of words in the Model_Answer \n",
    "total = 0\n",
    "for i in range(len(asag_df)):\n",
    "    list = asag_df['Model_Answer'][i].split()\n",
    "    lenght = len(list)\n",
    "    total += lenght\n",
    "\n",
    "avg = total/len(asag_df)\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "asag_df['Answer'] = asag_df['Answer'].apply(lambda x: x.lower())\n",
    "asag_df['Model Answer'] = asag_df['Model_Answer'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bert_similarity(base_answer, sample_answer):\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    tokenize_base_answer = sent_tokenize(base_answer)\n",
    "    base_answer_embedding = model.encode(tokenize_base_answer)\n",
    "    base_answer_embedding_mean = np.mean(np.array(base_answer_embedding), axis=0)\n",
    "\n",
    "    tokenize_sample_answer = sent_tokenize(sample_answer)\n",
    "    sample_answer_embedding = model.encode(tokenize_sample_answer)\n",
    "    sample_answer_embedding_mean = np.mean(np.array(sample_answer_embedding), axis=0)\n",
    "\n",
    "    cosine_similarity_score = cosine_similarity([base_answer_embedding_mean], [sample_answer_embedding_mean]).flatten()\n",
    "\n",
    "    print(cosine_similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are three types of software engineering: Agile, Waterfall and Spiral\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('three', 'CARDINAL'), ('Spiral', 'PRODUCT')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy for entity recognition in the answers\n",
    "import spacy\n",
    "\n",
    "# recognize entities in the asag_df\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def process_spacy_entities(answer):\n",
    "    print(answer)\n",
    "    doc = nlp(answer)\n",
    "    entities = [(X.text, X.label_) for X in doc.ents]\n",
    "    return entities\n",
    "\n",
    "process_spacy_entities(\"There are three types of software engineering: Agile, Waterfall and Spiral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76450104]\n"
     ]
    }
   ],
   "source": [
    "modelAnswer = asag_df['Model_Answer'][0]\n",
    "sampleAnswer = asag_df['Answer'][0]\n",
    "\n",
    "process_bert_similarity(modelAnswer, sampleAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the role of a prototype program in problem solving?\n",
      "\n",
      "To simulate the behaviour of portions of the desired software product. \n",
      "\n",
      "High risk problems are address in the prototype program to make sure that the program is feasible.  A prototype may also be used to show a company that the software can be possibly programmed.<br><br>\n",
      "\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "print(asag_df['Question'][0])\n",
    "print(asag_df['Model_Answer'][0])\n",
    "print(asag_df['Answer'][0])\n",
    "print(asag_df['Score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column Answer_Embeddings - type numpyArray\n",
    "asag_df['Answer_Embeddings'] = [[] for i in range(len(asag_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "dataFrame = pd.DataFrame({'Cosine_Similarity'})\n",
    "\n",
    "for i in range(100):\n",
    "    # add a row to the dataframe\n",
    "    cosine_simi = 9.44\n",
    "    dataFrame = dataFrame.append({'Cosine_Similarity': cosine_simi}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1953, 6)\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, 100, 2)            200       \n",
      "                                                                 \n",
      " bidirectional_18 (Bidirecti  (None, 128)              34304     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,278\n",
      "Trainable params: 35,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 20s 28ms/step - loss: 1.4692 - accuracy: 0.5211 - val_loss: 1.3274 - val_accuracy: 0.4936\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 1.3382 - accuracy: 0.5211 - val_loss: 1.3386 - val_accuracy: 0.4936\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 1.3293 - accuracy: 0.5230 - val_loss: 1.3310 - val_accuracy: 0.4936\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 1.3183 - accuracy: 0.5230 - val_loss: 1.3286 - val_accuracy: 0.4936\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 1.3203 - accuracy: 0.5230 - val_loss: 1.3270 - val_accuracy: 0.4936\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 1.3044 - accuracy: 0.5237 - val_loss: 1.3285 - val_accuracy: 0.4936\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 1.2920 - accuracy: 0.5205 - val_loss: 1.3110 - val_accuracy: 0.4885\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 1.2773 - accuracy: 0.5262 - val_loss: 1.3500 - val_accuracy: 0.4936\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 1.2697 - accuracy: 0.5269 - val_loss: 1.3149 - val_accuracy: 0.4859\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 1.2503 - accuracy: 0.5230 - val_loss: 1.3219 - val_accuracy: 0.4885\n",
      "-0.6378123348590163\n",
      "2.094836400817996\n"
     ]
    }
   ],
   "source": [
    "# Regression Model to predict the score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(asag_df['Answer'], asag_df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# tokenize the data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "# convert the text to sequence of integers\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "# pad the sequence to the same length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=100)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# convert the score to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train)\n",
    "y_test_onehot = to_categorical(y_test)\n",
    "\n",
    "print(y_train_onehot.shape)\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=100, output_dim=2, input_length=100))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train_onehot.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train_pad, y_train_onehot, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test_pad)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "# calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01337584 0.02832213 0.08284079 0.1348912  0.13908458 0.6014855 ]]\n"
     ]
    }
   ],
   "source": [
    "#predict for new Answer\n",
    "new_answer = \"The model is a good model\"\n",
    "new_answer_seq = tokenizer.texts_to_sequences([new_answer])\n",
    "new_answer_pad = pad_sequences(new_answer_seq, maxlen=100)\n",
    "\n",
    "\n",
    "# predict the score\n",
    "score = model.predict(new_answer_pad)\n",
    "print(score)\n",
    "\n",
    "\n",
    "score = np.argmax(score, axis=0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a8875a9de9d7ae50992e4bd370660b778ec8ba762c63430b991b7684d493a6c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
