{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Bidirectional, Flatten, Input, Lambda, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.metrics import sparse_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/improvedds_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ans_col = 'Model_Answer'\n",
    "ans_col = 'Answer'\n",
    "label_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_model_training(df, model_ans_col='Model_Answer', ans_col='Answer'):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing data...\")\n",
    "    df[model_ans_col] = data[model_ans_col].apply(lambda x: str(x).lower())\n",
    "    df[ans_col] = data[ans_col].apply(lambda x: str(x).lower())\n",
    "\n",
    "    df[model_ans_col] = df[model_ans_col].apply(lambda x: x.strip())\n",
    "    df[ans_col] = df[ans_col].apply(lambda x: x.strip())\n",
    "\n",
    "    df[model_ans_col] = df[model_ans_col].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    df[ans_col] = df[ans_col].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    #remove br tags\n",
    "    df[model_ans_col] = df[model_ans_col].apply(lambda x: x.replace('<br>', ' '))\n",
    "    df[ans_col] = df[ans_col].apply(lambda x: x.replace('<br>', ' '))\n",
    "    df[model_ans_col] = df[model_ans_col].apply(lambda x: x.replace('<br/>', ' '))\n",
    "    df[ans_col] = df[ans_col].apply(lambda x: x.replace('<br/>', ' '))\n",
    "\n",
    "    #remove multiple spaces\n",
    "    df[model_ans_col] = df[model_ans_col].apply(lambda x: x.replace('  ', ' '))\n",
    "    df[ans_col] = df[ans_col].apply(lambda x: x.replace('  ', ' '))\n",
    "\n",
    "    #remove newlines\n",
    "    df[model_ans_col] = df[model_ans_col].apply(lambda x: x.replace('\\n', ' '))\n",
    "    df[ans_col] = df[ans_col].apply(lambda x: x.replace('\\n', ' '))\n",
    "\n",
    "    print(\"Data preprocessing is done\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for deep learning model training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[[model_ans_col, ans_col]], data[label_col], test_size=0.2, random_state=286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\urllib\\request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1346\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[0;32m   1347\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m   1348\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\http\\client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\http\\client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1280\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\http\\client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1040\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\http\\client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\http\\client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mConnect to a host on a given (SSL) port.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1447\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\http\\client.py:946\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection(\n\u001b[0;32m    947\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhost,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address)\n\u001b[0;32m    948\u001b[0m \u001b[39m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\socket.py:823\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    822\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m getaddrinfo(host, port, \u001b[39m0\u001b[39;49m, SOCK_STREAM):\n\u001b[0;32m    824\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\socket.py:954\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    953\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 954\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    955\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\SLIIT\\Year 4\\Research\\2022-028\\Knowledge and Attitude Evaluation\\Answer Evaluation\\Deep Learning Approach\\data5 - withBertEncodingLayer.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SLIIT/Year%204/Research/2022-028/Knowledge%20and%20Attitude%20Evaluation/Answer%20Evaluation/Deep%20Learning%20Approach/data5%20-%20withBertEncodingLayer.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mstring)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/SLIIT/Year%204/Research/2022-028/Knowledge%20and%20Attitude%20Evaluation/Answer%20Evaluation/Deep%20Learning%20Approach/data5%20-%20withBertEncodingLayer.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m preprocessor \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mKerasLayer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SLIIT/Year%204/Research/2022-028/Knowledge%20and%20Attitude%20Evaluation/Answer%20Evaluation/Deep%20Learning%20Approach/data5%20-%20withBertEncodingLayer.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mhttps://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SLIIT/Year%204/Research/2022-028/Knowledge%20and%20Attitude%20Evaluation/Answer%20Evaluation/Deep%20Learning%20Approach/data5%20-%20withBertEncodingLayer.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m encoder_inputs \u001b[39m=\u001b[39m preprocessor(text_input)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SLIIT/Year%204/Research/2022-028/Knowledge%20and%20Attitude%20Evaluation/Answer%20Evaluation/Deep%20Learning%20Approach/data5%20-%20withBertEncodingLayer.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m encoder \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SLIIT/Year%204/Research/2022-028/Knowledge%20and%20Attitude%20Evaluation/Answer%20Evaluation/Deep%20Learning%20Approach/data5%20-%20withBertEncodingLayer.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SLIIT/Year%204/Research/2022-028/Knowledge%20and%20Attitude%20Evaluation/Answer%20Evaluation/Deep%20Learning%20Approach/data5%20-%20withBertEncodingLayer.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     trainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:153\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[0;32m    150\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_training_argument \u001b[39m=\u001b[39m func_has_training_argument(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func)\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:449\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 449\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\module_v2.py:92\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m     91\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected a string, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m handle)\n\u001b[1;32m---> 92\u001b[0m module_path \u001b[39m=\u001b[39m resolve(handle)\n\u001b[0;32m     93\u001b[0m is_hub_module_v1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(\n\u001b[0;32m     94\u001b[0m     native_module\u001b[39m.\u001b[39mget_module_proto_path(module_path))\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m tags \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m is_hub_module_v1:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\module_v2.py:47\u001b[0m, in \u001b[0;36mresolve\u001b[1;34m(handle)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve\u001b[39m(handle):\n\u001b[0;32m     24\u001b[0m   \u001b[39m\"\"\"Resolves a module handle into a path.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[39m  This function works both for plain TF2 SavedModels and the legacy TF1 Hub\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m    A string representing the Module path.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m   \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mresolver(handle)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\registry.py:51\u001b[0m, in \u001b[0;36mMultiImplRegister.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m impl \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impls):\n\u001b[0;32m     50\u001b[0m   \u001b[39mif\u001b[39;00m impl\u001b[39m.\u001b[39mis_supported(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     52\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     fails\u001b[39m.\u001b[39mappend(\u001b[39mtype\u001b[39m(impl)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\compressed_module_resolver.py:67\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__\u001b[1;34m(self, handle)\u001b[0m\n\u001b[0;32m     63\u001b[0m   response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_urlopen(request)\n\u001b[0;32m     64\u001b[0m   \u001b[39mreturn\u001b[39;00m resolver\u001b[39m.\u001b[39mDownloadManager(handle)\u001b[39m.\u001b[39mdownload_and_uncompress(\n\u001b[0;32m     65\u001b[0m       response, tmp_dir)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m resolver\u001b[39m.\u001b[39;49matomic_download(handle, download, module_dir,\n\u001b[0;32m     68\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lock_file_timeout_sec())\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\resolver.py:418\u001b[0m, in \u001b[0;36matomic_download\u001b[1;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[0;32m    416\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDownloading TF-Hub Module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, handle)\n\u001b[0;32m    417\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mMakeDirs(tmp_dir)\n\u001b[1;32m--> 418\u001b[0m download_fn(handle, tmp_dir)\n\u001b[0;32m    419\u001b[0m \u001b[39m# Write module descriptor to capture information about which module was\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39m# downloaded by whom and when. The file stored at the same level as a\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39m# directory in order to keep the content of the 'model_dir' exactly as it\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[39m# module caching protocol and no code in the TF-Hub library reads its\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[39m# content.\u001b[39;00m\n\u001b[0;32m    428\u001b[0m _write_module_descriptor_file(handle, module_dir)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\compressed_module_resolver.py:63\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__.<locals>.download\u001b[1;34m(handle, tmp_dir)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m\"\"\"Fetch a module via HTTP(S), handling redirect and download headers.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m request \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(\n\u001b[0;32m     62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_compressed_format_query(handle))\n\u001b[1;32m---> 63\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_urlopen(request)\n\u001b[0;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m resolver\u001b[39m.\u001b[39mDownloadManager(handle)\u001b[39m.\u001b[39mdownload_and_uncompress(\n\u001b[0;32m     65\u001b[0m     response, tmp_dir)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\tensorflow_hub\\resolver.py:522\u001b[0m, in \u001b[0;36mHttpResolverBase._call_urlopen\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_urlopen\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[0;32m    520\u001b[0m   \u001b[39m# Overriding this method allows setting SSL context in Python 3.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(request)\n\u001b[0;32m    523\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m     \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(request, context\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\urllib\\request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[0;32m    516\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[1;32m--> 517\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[0;32m    519\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[0;32m    520\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\urllib\\request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    533\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 534\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[0;32m    535\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[0;32m    536\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    537\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\urllib\\request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[0;32m   1390\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\research\\lib\\urllib\\request.py:1349\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[0;32m   1347\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m   1348\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1350\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m   1351\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",\n",
    "    trainable=False)\n",
    "outputs = encoder(encoder_inputs)\n",
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = tf.keras.Model(text_input, sequence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Layers\n",
    "input_model_answer = Input(shape=(1,), dtype=tf.string)\n",
    "input_answer = Input(shape=(1,), dtype=tf.string)\n",
    "#input_text_features = Input(shape=(2,) , dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_answer = embedding_model(input_model_answer)\n",
    "embedding_answer = embedding_model(input_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the differnce of the embedding vectors\n",
    "diff_model_ans = Lambda(\n",
    "        lambda x: x[0] - x[1])([embedding_model_answer, embedding_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the LSTM layer\n",
    "lstm_model_answer = Bidirectional(\n",
    "    LSTM(64, return_sequences=True))(diff_model_ans)\n",
    "\n",
    "lstm_answer = Bidirectional(\n",
    "    LSTM(64, return_sequences=True))(embedding_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dropout\n",
    "dropout_model_answer = Dropout(0.3)(lstm_model_answer)\n",
    "dropout_answer = Dropout(0.3)(lstm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the Dense layer\n",
    "#dense_model_answer = Dense(10, activation='relu')(dropout_model_answer)\n",
    "#dense_answer = Dense(10, activation='relu')(dropout_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_layer = Dense(60, activation='relu')(input_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the outputs\n",
    "#concatenate_model_answer = concatenate([dense_model_answer, dense_answer])\n",
    "concatenate_model_answer = concatenate([dropout_model_answer, dropout_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Dense layer\n",
    "dense_model1 = Dense(32, activation='relu')(concatenate_model_answer)\n",
    "\n",
    "# apply dropout\n",
    "dropout_model1 = Dropout(0.4)(dense_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the dimensionality\n",
    "#dense_model2 = Dense(20, activation='relu')(dropout_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include Flatten layer\n",
    "flatten_model_answer = Flatten()(dense_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_layer = concatenate([flatten_model_answer, feature_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_layer = Dense(5, activation='relu')(concat_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Dense layer - output layer\n",
    "#output_model_answer = Dense(3, activation='softmax')(final_layer)\n",
    "output_model_answer = Dense(3, activation='softmax')(flatten_model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "#model = Model(inputs=[input_model_answer, input_answer, input_text_features], outputs=output_model_answer)\n",
    "model = Model(inputs=[input_model_answer, input_answer], outputs=output_model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "# logs about the training process\n",
    "# accuracy and loss are plotted in the TensorBoard\n",
    "log_dir = \"logs/fit/\" + str(int(time.time()))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class weights according to the number of samples in each class\n",
    "num_samples_class_0 = len(X_train[y_train[:, 0] == 1.0])\n",
    "num_samples_class_1 = len(X_train[y_train[:, 1] == 1.0])\n",
    "num_samples_class_2 = len(X_train[y_train[:, 2] == 1.0])\n",
    "\n",
    "\n",
    "class_weights = {0: num_samples_class_0 / (num_samples_class_0 + num_samples_class_1 + num_samples_class_2),\n",
    "                    1: num_samples_class_1 / (num_samples_class_0 + num_samples_class_1 + num_samples_class_2),                                                     \n",
    "                    2: num_samples_class_2 / (num_samples_class_0 + num_samples_class_1 + num_samples_class_2)}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1348/1348 [==============================] - 682s 459ms/step - loss: 0.5492 - accuracy: 0.7847 - val_loss: 0.2950 - val_accuracy: 0.8968\n",
      "Epoch 2/50\n",
      "1348/1348 [==============================] - 617s 458ms/step - loss: 0.1870 - accuracy: 0.9384 - val_loss: 0.1055 - val_accuracy: 0.9683\n",
      "Epoch 3/50\n",
      "1348/1348 [==============================] - 618s 458ms/step - loss: 0.0701 - accuracy: 0.9797 - val_loss: 0.0830 - val_accuracy: 0.9757\n",
      "Epoch 4/50\n",
      "1348/1348 [==============================] - 618s 458ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0443 - val_accuracy: 0.9876\n",
      "Epoch 5/50\n",
      "1348/1348 [==============================] - 616s 457ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0638 - val_accuracy: 0.9801\n",
      "Epoch 6/50\n",
      "1348/1348 [==============================] - 618s 458ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0358 - val_accuracy: 0.9915\n",
      "Epoch 7/50\n",
      "1348/1348 [==============================] - 621s 461ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.0604 - val_accuracy: 0.9803\n",
      "Epoch 8/50\n",
      "1348/1348 [==============================] - 615s 456ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0441 - val_accuracy: 0.9876\n",
      "Epoch 9/50\n",
      "1348/1348 [==============================] - 617s 458ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0375 - val_accuracy: 0.9900\n",
      "Epoch 10/50\n",
      "1348/1348 [==============================] - 617s 458ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0354 - val_accuracy: 0.9920\n",
      "Epoch 11/50\n",
      "1348/1348 [==============================] - 618s 458ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0802 - val_accuracy: 0.9783\n",
      "Epoch 12/50\n",
      "1348/1348 [==============================] - 617s 458ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0266 - val_accuracy: 0.9915\n",
      "Epoch 13/50\n",
      "1348/1348 [==============================] - 618s 458ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0223 - val_accuracy: 0.9939\n",
      "Epoch 14/50\n",
      "1348/1348 [==============================] - 617s 458ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0543 - val_accuracy: 0.9839\n",
      "Epoch 15/50\n",
      "1348/1348 [==============================] - 686s 509ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0192 - val_accuracy: 0.9939\n",
      "Epoch 16/50\n",
      "1348/1348 [==============================] - 3866s 3s/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.0463 - val_accuracy: 0.9876\n",
      "Epoch 17/50\n",
      "1348/1348 [==============================] - 644s 478ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0361 - val_accuracy: 0.9907\n",
      "Epoch 18/50\n",
      "1348/1348 [==============================] - 642s 476ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0211 - val_accuracy: 0.9942\n",
      "Epoch 19/50\n",
      "1348/1348 [==============================] - 642s 476ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0293 - val_accuracy: 0.9922\n",
      "Epoch 20/50\n",
      "1348/1348 [==============================] - 649s 481ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0322 - val_accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "#history = model.fit([X_train[model_ans_col], X_train[ans_col], X_train[['LengthRatio', 'Cosine_Similarity']]], y_train, epochs=50, batch_size=32,\n",
    "#              validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5), tensorboard_callback])\n",
    "history = model.fit([X_train[model_ans_col], X_train[ans_col]], y_train, epochs=50, batch_size=64,\n",
    "              validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5), tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.62%\n",
      "Loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# scores = model.evaluate(\n",
    "#         [X_train[model_ans_col], X_train[ans_col], X_train[['LengthRati', 'Cosine_Similarity']]], y_train, verbose=0)\n",
    "scores = model.evaluate(\n",
    "        [X_train[model_ans_col], X_train[ans_col]], y_train, verbose=0)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Loss: %.2f\" % scores[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 159s 754ms/step - loss: 0.0246 - accuracy: 0.9914\n",
      "Test Accuracy: 99.14%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: %.2f%%\" % (model.evaluate(\n",
    "        [X_test[model_ans_col], X_test[ans_col]], y_test, verbose=1)[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: 2\n"
     ]
    }
   ],
   "source": [
    "model_ans_p = \"When the array is not sorted\"\n",
    "ans_p = \"When the array is not in order\"\n",
    "\n",
    "def get_length_ration(model_ans, ans):\n",
    "    return len(ans)/len(model_ans)\n",
    "\n",
    "cosine_similarity_p = 0.912\n",
    "length_ration_p = get_length_ration(model_ans_p, ans_p)\n",
    "\n",
    "testdf = pd.DataFrame(columns=['Model_Answer', 'Answer', 'LengthRatio', 'Cosine_Similarity'])\n",
    "testdf.loc[0] = [model_ans_p, ans_p, length_ration_p, cosine_similarity_p]\n",
    "\n",
    "prediction = model.predict([testdf[model_ans_col].iloc[0:1], testdf[ans_col].iloc[0:1]])\n",
    "print(\"Category:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4031264e-04, 3.2323944e-06, 9.9955648e-01]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "import datetime\n",
    "isSave = 'y'\n",
    "\n",
    "if isSave == 'y':\n",
    "    model.save('./Models/model' + str(datetime.datetime.now().timestamp().__round__()) + '.h5')\n",
    "    print(\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6dd968e44b48f26426fe23fbd93cd49fd04e6edb7e547023c0509ffaabbd7da7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
