{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_network.ipynb","provenance":[{"file_id":"1-Nl_wDmR2Lt1ywve2LRKPD2zDE5jWBRi","timestamp":1648730452743}],"authorship_tag":"ABX9TyPXq4AEfBibNYJwJWguphzw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LGGIUBoV_g2v","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1650990634868,"user_tz":-330,"elapsed":3288,"user":{"displayName":"Tharusha Ranasinghe","userId":"01304718387153704633"}},"outputId":"ecef7004-4f9a-4fee-ee28-9afed2f55b93"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-64493fac2529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'get_features'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# Imports\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n","from keras.models import load_model\n","import get_features\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import os\n","from sklearn.metrics import classification_report\n","\n","def create_mlp(num_labels):\n","\n","    model = Sequential()\n","    model.add(Dense(256,input_shape = (40,)))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(256,input_shape = (40,)))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(num_labels))\n","    model.add(Activation('softmax'))\n","    return model\n","\n","def create_cnn(num_labels):\n","\n","    model = Sequential()\n","    model.add(Conv1D(64, 3, activation='relu', input_shape=(40, 1)))\n","    model.add(Conv1D(64, 3, activation='relu'))\n","    model.add(MaxPooling1D(3))\n","    model.add(Conv1D(128, 3, activation='relu'))\n","    model.add(Conv1D(128, 3, activation='relu'))\n","    model.add(GlobalAveragePooling1D())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_labels))\n","    model.add(Activation('softmax'))\n","    return model\n","\n","def train(model,X_train, X_test, y_train, y_test,model_file):    \n","    \n","    # compile the model \n","    model.compile(loss = 'categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n","\n","    print(model.summary())\n","\n","    print(\"training for 100 epochs with batch size 32\")\n","   \n","    model.fit(X_train,y_train,batch_size= 10, epochs = 100, validation_data=(X_test,y_test))\n","    \n","    # save model to disk\n","    print(\"Saving model to disk\")\n","    model.save(model_file)\n","\n","    # y_pred = model.predict_classes(X_test, batch_size=8, verbose=1)\n","    predict_x=model.predict(X_test) \n","    classes_x=np.argmax(predict_x,axis=1)\n","    y_test = np.argmax(y_test, axis=1)\n","    y_pred_arg_max = []\n","    print(\"--------------->>>>>>>>>>>>>>>\")\n","    print(y_pred)\n","    print(y_test)\n","\n","    print(classification_report(y_test, y_pred))\n","\n","def compute(X_test,y_test,model_file):\n","\n","    # load model from disk\n","    loaded_model = load_model(model_file)\n","    score = loaded_model.evaluate(X_test,y_test)\n","    return score[0],score[1]*100\n","\n","def predict(filename,le,model_file):\n","\n","    model = load_model(model_file)\n","    prediction_feature = get_features.get_features(filename)\n","    if len(prediction_feature) == 0:\n","        return {\"pred\": \"\", \"probability\": str(0)}\n","    if model_file == \"trained_mlp.h5\":\n","        prediction_feature = np.array([prediction_feature])\n","    elif model_file == \"trained_cnn.h5\":    \n","        prediction_feature = np.expand_dims(np.array([prediction_feature]),axis=2)\n","\n","    predicted_vector = model.predict_classes(prediction_feature)\n","    predicted_class = le.inverse_transform(predicted_vector)\n","    sub_dirs = os.listdir('data')\n","    sub_dirs.sort()\n","    print(\"Predicted class\",sub_dirs[predicted_class[0]])\n","    predicted_proba_vector = model.predict_proba([prediction_feature])\n","\n","    word = \"\"\n","    probability = 0\n","    predicted_proba = predicted_proba_vector[0]\n","    for i in range(len(predicted_proba)): \n","        category = le.inverse_transform(np.array([i]))\n","        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )\n","        if (predicted_proba[i] > probability):\n","            probability = predicted_proba[i]\n","            word = sub_dirs[predicted_class[0]]\n","            print(\"Selected word: \", word)\n","\n","    return {\"pred\": word, \"probability\": str(probability)}\n"]}]}